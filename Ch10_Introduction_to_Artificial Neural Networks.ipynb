{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Biological to Artifical Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Artifical Neural Networks fequently out-perform other machine learning algorithms\n",
    "2. Large amounts of computing power is needed to train ANNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Biological Neurons*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neurons structured in successive layers can perform highly complex computations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Logical Computations with Neurons*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An **artificial neuron** has multiple binary inputs and only one binary output. If you assume that such a neuron can only be activated two active inputs, then it is possible to construct a network that can compute any logical expression. Example: logical AND can be computed if input A and input B have only one connection to output C. This works as both A and B must be active to activate C. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *The Preceptron*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Preceptron** is a simple ANN architecture that is based on the *linear threshold unit* (LTU), an artifical neuron that has weighted numerical inputs and a single output dependant on some function (i.e. given input of the form $z = w_1 x_1 + \\, ... \\, + w_n x_n$ the LHU applies a step function to the input to get the result: $h_w(x) = step(z) = step(w^T \\cdot x)$). A common step function is the [Heavyside](https://en.wikipedia.org/wiki/Heaviside_step_function) function. \n",
    "\n",
    "A single LTU can be used to perform simple binary classification. \n",
    "\n",
    "A preceptron is simply an ANN composed of a single layer of LTUs that get their input from a layer of *input neurons* that simply pass values and a single *bias* neurons that always outputs 1. \n",
    "\n",
    "Precpton learning is summarized as \"Cells that fire together, wire together\". This basically means if two neurons output the same value and the network predicts the right result, then the weight between the two is increased. \n",
    "\n",
    "**Precptron learning rule**:\n",
    "\n",
    "$\\large w_{i,j}^{(\\text{next step})} = w_{i,j} + \\eta \\, (\\hat{y_j} - y_j) x_i$\n",
    "\n",
    "where: \n",
    "* $w_{i,j}$ is the connection weight between i-th input neuron and j-th output neuron\n",
    "* $x_i$ is the i-th input of the current training instance\n",
    "* $\\hat{y_j}$ is the output of the j-th output neuron for the current training instance\n",
    "* $y_j$ is the output target of the j-th output neuron for the current training instance\n",
    "* $\\eta$ is the learning rate\n",
    "\n",
    "The decision boundary is linear so preceptrons are incapable of learning complex patterns. However by the *preceptron convergence theorem*, if the training instances are [linearly separable](https://en.wikipedia.org/wiki/Linear_separability) then the algorithm will converge to a solution. \n",
    "\n",
    "Scikit comes with an implementation of the preceptron built in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "print (per_clf.predict([[2, 0.5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the weakness of preceptrons can be eliminated if you simple stack multiple layers of them (a **Multi-layered Preceptron (MLP)**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Multi-Layer Preceptron and Backpropogation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP: one passthrough input layer, one or more layers of LTUs called *hidden layers*, and one final layer of LTUs called the *output layer*. Every layer except the output layer has a bias neuron. When a layer has multiple hidden layers its called a *deep neural network*. \n",
    "\n",
    "For each training instance the *back propogatio algorithm* first makes a prediction (forward pass), measures the error, then goes through each layer in reverse to measure the error contribution from each connection (reverse pass), and finally slightly tweaks the connection weights to reduce the error (Gradient Descent step). The backprogoation algorithm cannot be used with the heavyside step function. It can however use any of the following:\n",
    "* [ReLU Function](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\n",
    "* [Logistic Function](https://en.wikipedia.org/wiki/Logistic_function)\n",
    "* [Hyperbolic Tangent Function](http://mathworld.wolfram.com/HyperbolicTangent.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an MLP with TensorFlow's High Level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to train a MLP with tensorflow is use the TF.Learn API. The following code trains an MLP with two hidden layers (300 and 100 nodes each) and a softmax output of 10 nodes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "y_train = mnist.train.labels.astype(\"int\")\n",
    "y_test = mnist.test.labels.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_tf_random_seed': 42, '_task_type': None, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_secs': 600, '_is_chief': True, '_save_checkpoints_steps': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000014EF536F0F0>, '_model_dir': None, '_evaluation_master': '', '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_num_ps_replicas': 0, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_master': '', '_num_worker_replicas': 0, '_task_id': 0, '_environment': 'local'}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\hugoj\\AppData\\Local\\Temp\\tmpims7vzmp\n",
      "WARNING:tensorflow:From C:\\Users\\hugoj\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\hugoj\\AppData\\Local\\Temp\\tmpims7vzmp\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 2.36404\n",
      "INFO:tensorflow:global_step/sec: 432.388\n",
      "INFO:tensorflow:step = 101, loss = 0.311432 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.747\n",
      "INFO:tensorflow:step = 201, loss = 0.265409 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.255\n",
      "INFO:tensorflow:step = 301, loss = 0.408733 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.79\n",
      "INFO:tensorflow:step = 401, loss = 0.244357 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.627\n",
      "INFO:tensorflow:step = 501, loss = 0.238858 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.275\n",
      "INFO:tensorflow:step = 601, loss = 0.091827 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.654\n",
      "INFO:tensorflow:step = 701, loss = 0.123374 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.823\n",
      "INFO:tensorflow:step = 801, loss = 0.196473 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.366\n",
      "INFO:tensorflow:step = 901, loss = 0.0932024 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.932\n",
      "INFO:tensorflow:step = 1001, loss = 0.196834 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.661\n",
      "INFO:tensorflow:step = 1101, loss = 0.194408 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.845\n",
      "INFO:tensorflow:step = 1201, loss = 0.152048 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.12\n",
      "INFO:tensorflow:step = 1301, loss = 0.149761 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.896\n",
      "INFO:tensorflow:step = 1401, loss = 0.0647763 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.467\n",
      "INFO:tensorflow:step = 1501, loss = 0.0727728 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.57\n",
      "INFO:tensorflow:step = 1601, loss = 0.120371 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.851\n",
      "INFO:tensorflow:step = 1701, loss = 0.0426907 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.612\n",
      "INFO:tensorflow:step = 1801, loss = 0.148324 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.704\n",
      "INFO:tensorflow:step = 1901, loss = 0.073107 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.764\n",
      "INFO:tensorflow:step = 2001, loss = 0.0638611 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.434\n",
      "INFO:tensorflow:step = 2101, loss = 0.0233887 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.555\n",
      "INFO:tensorflow:step = 2201, loss = 0.0329285 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.906\n",
      "INFO:tensorflow:step = 2301, loss = 0.0519914 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.211\n",
      "INFO:tensorflow:step = 2401, loss = 0.0577268 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.515\n",
      "INFO:tensorflow:step = 2501, loss = 0.084227 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.656\n",
      "INFO:tensorflow:step = 2601, loss = 0.0315869 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.57\n",
      "INFO:tensorflow:step = 2701, loss = 0.0121763 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.232\n",
      "INFO:tensorflow:step = 2801, loss = 0.0630663 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.987\n",
      "INFO:tensorflow:step = 2901, loss = 0.0913481 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.033\n",
      "INFO:tensorflow:step = 3001, loss = 0.0138151 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.253\n",
      "INFO:tensorflow:step = 3101, loss = 0.0337465 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.324\n",
      "INFO:tensorflow:step = 3201, loss = 0.0132512 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.527\n",
      "INFO:tensorflow:step = 3301, loss = 0.0321816 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.93\n",
      "INFO:tensorflow:step = 3401, loss = 0.143895 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.341\n",
      "INFO:tensorflow:step = 3501, loss = 0.0897496 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.775\n",
      "INFO:tensorflow:step = 3601, loss = 0.157295 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.864\n",
      "INFO:tensorflow:step = 3701, loss = 0.03669 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.588\n",
      "INFO:tensorflow:step = 3801, loss = 0.0122543 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.394\n",
      "INFO:tensorflow:step = 3901, loss = 0.152421 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.8\n",
      "INFO:tensorflow:step = 4001, loss = 0.107787 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.3\n",
      "INFO:tensorflow:step = 4101, loss = 0.0485792 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.668\n",
      "INFO:tensorflow:step = 4201, loss = 0.0590532 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.841\n",
      "INFO:tensorflow:step = 4301, loss = 0.158572 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.712\n",
      "INFO:tensorflow:step = 4401, loss = 0.114563 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.311\n",
      "INFO:tensorflow:step = 4501, loss = 0.0187132 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.937\n",
      "INFO:tensorflow:step = 4601, loss = 0.0182185 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.937\n",
      "INFO:tensorflow:step = 4701, loss = 0.00904818 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.211\n",
      "INFO:tensorflow:step = 4801, loss = 0.0186206 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.963\n",
      "INFO:tensorflow:step = 4901, loss = 0.0834735 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.259\n",
      "INFO:tensorflow:step = 5001, loss = 0.0451745 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.033\n",
      "INFO:tensorflow:step = 5101, loss = 0.00802126 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.936\n",
      "INFO:tensorflow:step = 5201, loss = 0.0236921 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.379\n",
      "INFO:tensorflow:step = 5301, loss = 0.040991 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.418\n",
      "INFO:tensorflow:step = 5401, loss = 0.0607277 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.812\n",
      "INFO:tensorflow:step = 5501, loss = 0.0441553 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.907\n",
      "INFO:tensorflow:step = 5601, loss = 0.0769239 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.945\n",
      "INFO:tensorflow:step = 5701, loss = 0.0198653 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.477\n",
      "INFO:tensorflow:step = 5801, loss = 0.00881232 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.597\n",
      "INFO:tensorflow:step = 5901, loss = 0.110585 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.435\n",
      "INFO:tensorflow:step = 6001, loss = 0.0857567 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.392\n",
      "INFO:tensorflow:step = 6101, loss = 0.0120617 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.587\n",
      "INFO:tensorflow:step = 6201, loss = 0.022921 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.909\n",
      "INFO:tensorflow:step = 6301, loss = 0.0707142 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.676\n",
      "INFO:tensorflow:step = 6401, loss = 0.0212568 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.141\n",
      "INFO:tensorflow:step = 6501, loss = 0.00796753 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.921\n",
      "INFO:tensorflow:step = 6601, loss = 0.0281497 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.247\n",
      "INFO:tensorflow:step = 6701, loss = 0.0216029 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.355\n",
      "INFO:tensorflow:step = 6801, loss = 0.0129809 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.396\n",
      "INFO:tensorflow:step = 6901, loss = 0.0126797 (0.239 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 452.507\n",
      "INFO:tensorflow:step = 7001, loss = 0.0166421 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.027\n",
      "INFO:tensorflow:step = 7101, loss = 0.00448675 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.203\n",
      "INFO:tensorflow:step = 7201, loss = 0.0508161 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.814\n",
      "INFO:tensorflow:step = 7301, loss = 0.00550252 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.617\n",
      "INFO:tensorflow:step = 7401, loss = 0.0154965 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.523\n",
      "INFO:tensorflow:step = 7501, loss = 0.004822 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.782\n",
      "INFO:tensorflow:step = 7601, loss = 0.0131625 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.137\n",
      "INFO:tensorflow:step = 7701, loss = 0.00680886 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.153\n",
      "INFO:tensorflow:step = 7801, loss = 0.00376618 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.125\n",
      "INFO:tensorflow:step = 7901, loss = 0.0131479 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.995\n",
      "INFO:tensorflow:step = 8001, loss = 0.00631671 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.019\n",
      "INFO:tensorflow:step = 8101, loss = 0.0245089 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.27\n",
      "INFO:tensorflow:step = 8201, loss = 0.0208505 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.407\n",
      "INFO:tensorflow:step = 8301, loss = 0.04197 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.929\n",
      "INFO:tensorflow:step = 8401, loss = 0.0136715 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.571\n",
      "INFO:tensorflow:step = 8501, loss = 0.0110502 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.28\n",
      "INFO:tensorflow:step = 8601, loss = 0.00604934 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.308\n",
      "INFO:tensorflow:step = 8701, loss = 0.0065747 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.911\n",
      "INFO:tensorflow:step = 8801, loss = 0.00738027 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.372\n",
      "INFO:tensorflow:step = 8901, loss = 0.00280681 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.958\n",
      "INFO:tensorflow:step = 9001, loss = 0.015022 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.791\n",
      "INFO:tensorflow:step = 9101, loss = 0.00840854 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.521\n",
      "INFO:tensorflow:step = 9201, loss = 0.00372718 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.605\n",
      "INFO:tensorflow:step = 9301, loss = 0.0134235 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.429\n",
      "INFO:tensorflow:step = 9401, loss = 0.034022 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.514\n",
      "INFO:tensorflow:step = 9501, loss = 0.00841827 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.678\n",
      "INFO:tensorflow:step = 9601, loss = 0.015819 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.409\n",
      "INFO:tensorflow:step = 9701, loss = 0.0086599 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.813\n",
      "INFO:tensorflow:step = 9801, loss = 0.00439482 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.557\n",
      "INFO:tensorflow:step = 9901, loss = 0.0174038 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.913\n",
      "INFO:tensorflow:step = 10001, loss = 0.0208312 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.985\n",
      "INFO:tensorflow:step = 10101, loss = 0.00381713 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.892\n",
      "INFO:tensorflow:step = 10201, loss = 0.00676587 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.728\n",
      "INFO:tensorflow:step = 10301, loss = 0.00574352 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.69\n",
      "INFO:tensorflow:step = 10401, loss = 0.00939435 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.032\n",
      "INFO:tensorflow:step = 10501, loss = 0.00275532 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.248\n",
      "INFO:tensorflow:step = 10601, loss = 0.00952128 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.693\n",
      "INFO:tensorflow:step = 10701, loss = 0.0303758 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.984\n",
      "INFO:tensorflow:step = 10801, loss = 0.0115768 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.23\n",
      "INFO:tensorflow:step = 10901, loss = 0.00465772 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.813\n",
      "INFO:tensorflow:step = 11001, loss = 0.0293584 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.186\n",
      "INFO:tensorflow:step = 11101, loss = 0.00492727 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.294\n",
      "INFO:tensorflow:step = 11201, loss = 0.000853527 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.888\n",
      "INFO:tensorflow:step = 11301, loss = 0.0139262 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.878\n",
      "INFO:tensorflow:step = 11401, loss = 0.00881559 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.214\n",
      "INFO:tensorflow:step = 11501, loss = 0.0186049 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.748\n",
      "INFO:tensorflow:step = 11601, loss = 0.000492324 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.298\n",
      "INFO:tensorflow:step = 11701, loss = 0.00230341 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.797\n",
      "INFO:tensorflow:step = 11801, loss = 0.000418936 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.975\n",
      "INFO:tensorflow:step = 11901, loss = 0.00709947 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.618\n",
      "INFO:tensorflow:step = 12001, loss = 0.000176346 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.058\n",
      "INFO:tensorflow:step = 12101, loss = 0.00352114 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.042\n",
      "INFO:tensorflow:step = 12201, loss = 0.00409825 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.894\n",
      "INFO:tensorflow:step = 12301, loss = 0.00442711 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.605\n",
      "INFO:tensorflow:step = 12401, loss = 0.000686727 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.517\n",
      "INFO:tensorflow:step = 12501, loss = 0.00342111 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.05\n",
      "INFO:tensorflow:step = 12601, loss = 0.00143894 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.496\n",
      "INFO:tensorflow:step = 12701, loss = 0.00396524 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.049\n",
      "INFO:tensorflow:step = 12801, loss = 0.00715362 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.855\n",
      "INFO:tensorflow:step = 12901, loss = 0.00564594 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.846\n",
      "INFO:tensorflow:step = 13001, loss = 0.00317152 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.116\n",
      "INFO:tensorflow:step = 13101, loss = 0.00411803 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.76\n",
      "INFO:tensorflow:step = 13201, loss = 0.00683057 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.376\n",
      "INFO:tensorflow:step = 13301, loss = 0.00482892 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.987\n",
      "INFO:tensorflow:step = 13401, loss = 0.00194253 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.686\n",
      "INFO:tensorflow:step = 13501, loss = 0.00725991 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.326\n",
      "INFO:tensorflow:step = 13601, loss = 0.00496594 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.457\n",
      "INFO:tensorflow:step = 13701, loss = 0.00231069 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.361\n",
      "INFO:tensorflow:step = 13801, loss = 0.00758488 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.022\n",
      "INFO:tensorflow:step = 13901, loss = 0.00351695 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.796\n",
      "INFO:tensorflow:step = 14001, loss = 0.00250569 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.366\n",
      "INFO:tensorflow:step = 14101, loss = 0.00576778 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.737\n",
      "INFO:tensorflow:step = 14201, loss = 0.0106178 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.571\n",
      "INFO:tensorflow:step = 14301, loss = 0.00184563 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.337\n",
      "INFO:tensorflow:step = 14401, loss = 0.000657787 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.176\n",
      "INFO:tensorflow:step = 14501, loss = 0.000907568 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.568\n",
      "INFO:tensorflow:step = 14601, loss = 0.00308903 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.036\n",
      "INFO:tensorflow:step = 14701, loss = 0.000958802 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.884\n",
      "INFO:tensorflow:step = 14801, loss = 0.00119474 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.093\n",
      "INFO:tensorflow:step = 14901, loss = 0.00213329 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.055\n",
      "INFO:tensorflow:step = 15001, loss = 0.0011101 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.607\n",
      "INFO:tensorflow:step = 15101, loss = 0.00242632 (0.216 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 445.94\n",
      "INFO:tensorflow:step = 15201, loss = 0.00159225 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.181\n",
      "INFO:tensorflow:step = 15301, loss = 0.0014488 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.529\n",
      "INFO:tensorflow:step = 15401, loss = 0.00376972 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.421\n",
      "INFO:tensorflow:step = 15501, loss = 0.00406733 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.105\n",
      "INFO:tensorflow:step = 15601, loss = 0.00472252 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.989\n",
      "INFO:tensorflow:step = 15701, loss = 0.0146699 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.582\n",
      "INFO:tensorflow:step = 15801, loss = 0.00153426 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.716\n",
      "INFO:tensorflow:step = 15901, loss = 0.000447847 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.012\n",
      "INFO:tensorflow:step = 16001, loss = 0.00656253 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.373\n",
      "INFO:tensorflow:step = 16101, loss = 0.0043496 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.536\n",
      "INFO:tensorflow:step = 16201, loss = 7.70298e-05 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.612\n",
      "INFO:tensorflow:step = 16301, loss = 0.00260926 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.48\n",
      "INFO:tensorflow:step = 16401, loss = 0.00155471 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.777\n",
      "INFO:tensorflow:step = 16501, loss = 0.0015937 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.372\n",
      "INFO:tensorflow:step = 16601, loss = 0.00472044 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.603\n",
      "INFO:tensorflow:step = 16701, loss = 0.00249327 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.077\n",
      "INFO:tensorflow:step = 16801, loss = 0.00237052 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.244\n",
      "INFO:tensorflow:step = 16901, loss = 0.00251921 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.609\n",
      "INFO:tensorflow:step = 17001, loss = 0.00285329 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.514\n",
      "INFO:tensorflow:step = 17101, loss = 0.000563493 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.571\n",
      "INFO:tensorflow:step = 17201, loss = 0.00264452 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.517\n",
      "INFO:tensorflow:step = 17301, loss = 0.000915113 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.708\n",
      "INFO:tensorflow:step = 17401, loss = 0.00186997 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.759\n",
      "INFO:tensorflow:step = 17501, loss = 0.00155757 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.132\n",
      "INFO:tensorflow:step = 17601, loss = 0.000356618 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.318\n",
      "INFO:tensorflow:step = 17701, loss = 0.000703532 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.613\n",
      "INFO:tensorflow:step = 17801, loss = 0.000502199 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.49\n",
      "INFO:tensorflow:step = 17901, loss = 0.00201421 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.369\n",
      "INFO:tensorflow:step = 18001, loss = 0.00172619 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.47\n",
      "INFO:tensorflow:step = 18101, loss = 0.000986052 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.808\n",
      "INFO:tensorflow:step = 18201, loss = 0.00447541 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.036\n",
      "INFO:tensorflow:step = 18301, loss = 0.0146146 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.021\n",
      "INFO:tensorflow:step = 18401, loss = 0.00289675 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.34\n",
      "INFO:tensorflow:step = 18501, loss = 0.0022742 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.785\n",
      "INFO:tensorflow:step = 18601, loss = 0.00423942 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.124\n",
      "INFO:tensorflow:step = 18701, loss = 0.000945454 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.163\n",
      "INFO:tensorflow:step = 18801, loss = 0.00149365 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.856\n",
      "INFO:tensorflow:step = 18901, loss = 0.00309862 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.276\n",
      "INFO:tensorflow:step = 19001, loss = 0.00134573 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.757\n",
      "INFO:tensorflow:step = 19101, loss = 0.000693691 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.209\n",
      "INFO:tensorflow:step = 19201, loss = 0.000465131 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.296\n",
      "INFO:tensorflow:step = 19301, loss = 0.00558755 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.812\n",
      "INFO:tensorflow:step = 19401, loss = 0.000528183 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.792\n",
      "INFO:tensorflow:step = 19501, loss = 0.00208042 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.908\n",
      "INFO:tensorflow:step = 19601, loss = 0.000694155 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.233\n",
      "INFO:tensorflow:step = 19701, loss = 0.000119371 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.152\n",
      "INFO:tensorflow:step = 19801, loss = 0.00051242 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.415\n",
      "INFO:tensorflow:step = 19901, loss = 0.00184305 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.915\n",
      "INFO:tensorflow:step = 20001, loss = 0.00206445 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.347\n",
      "INFO:tensorflow:step = 20101, loss = 0.0003063 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.567\n",
      "INFO:tensorflow:step = 20201, loss = 0.00195141 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.466\n",
      "INFO:tensorflow:step = 20301, loss = 0.000959544 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.496\n",
      "INFO:tensorflow:step = 20401, loss = 0.00013434 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.582\n",
      "INFO:tensorflow:step = 20501, loss = 0.0003517 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.428\n",
      "INFO:tensorflow:step = 20601, loss = 0.00149112 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.7\n",
      "INFO:tensorflow:step = 20701, loss = 0.00112818 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.613\n",
      "INFO:tensorflow:step = 20801, loss = 0.00154887 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.965\n",
      "INFO:tensorflow:step = 20901, loss = 0.00139391 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.453\n",
      "INFO:tensorflow:step = 21001, loss = 0.00281828 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.187\n",
      "INFO:tensorflow:step = 21101, loss = 0.00136329 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.696\n",
      "INFO:tensorflow:step = 21201, loss = 0.00240587 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.888\n",
      "INFO:tensorflow:step = 21301, loss = 0.00113844 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.439\n",
      "INFO:tensorflow:step = 21401, loss = 0.00262636 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.351\n",
      "INFO:tensorflow:step = 21501, loss = 0.000237559 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.647\n",
      "INFO:tensorflow:step = 21601, loss = 0.00151222 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.271\n",
      "INFO:tensorflow:step = 21701, loss = 0.000995086 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.329\n",
      "INFO:tensorflow:step = 21801, loss = 0.000349444 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.695\n",
      "INFO:tensorflow:step = 21901, loss = 0.000656097 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.459\n",
      "INFO:tensorflow:step = 22001, loss = 0.000148364 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.773\n",
      "INFO:tensorflow:step = 22101, loss = 0.000531831 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.495\n",
      "INFO:tensorflow:step = 22201, loss = 0.00140872 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.281\n",
      "INFO:tensorflow:step = 22301, loss = 0.00243447 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.93\n",
      "INFO:tensorflow:step = 22401, loss = 0.00220339 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.574\n",
      "INFO:tensorflow:step = 22501, loss = 0.00157356 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.407\n",
      "INFO:tensorflow:step = 22601, loss = 0.00364198 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.506\n",
      "INFO:tensorflow:step = 22701, loss = 0.000852597 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.173\n",
      "INFO:tensorflow:step = 22801, loss = 0.00109362 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.139\n",
      "INFO:tensorflow:step = 22901, loss = 0.00240539 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.193\n",
      "INFO:tensorflow:step = 23001, loss = 0.000654596 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.281\n",
      "INFO:tensorflow:step = 23101, loss = 0.00295467 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.11\n",
      "INFO:tensorflow:step = 23201, loss = 0.00217089 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 23301, loss = 0.00169613 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.098\n",
      "INFO:tensorflow:step = 23401, loss = 0.000720154 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.592\n",
      "INFO:tensorflow:step = 23501, loss = 0.000805685 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.162\n",
      "INFO:tensorflow:step = 23601, loss = 0.000631053 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.401\n",
      "INFO:tensorflow:step = 23701, loss = 0.000255326 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.806\n",
      "INFO:tensorflow:step = 23801, loss = 0.00180432 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.99\n",
      "INFO:tensorflow:step = 23901, loss = 0.000976085 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.591\n",
      "INFO:tensorflow:step = 24001, loss = 0.00113664 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.03\n",
      "INFO:tensorflow:step = 24101, loss = 0.000741892 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.635\n",
      "INFO:tensorflow:step = 24201, loss = 0.000928554 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.345\n",
      "INFO:tensorflow:step = 24301, loss = 0.000218442 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.185\n",
      "INFO:tensorflow:step = 24401, loss = 0.00173174 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.636\n",
      "INFO:tensorflow:step = 24501, loss = 0.000569286 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.644\n",
      "INFO:tensorflow:step = 24601, loss = 0.000322807 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.396\n",
      "INFO:tensorflow:step = 24701, loss = 0.00111121 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.378\n",
      "INFO:tensorflow:step = 24801, loss = 0.00132868 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.317\n",
      "INFO:tensorflow:step = 24901, loss = 0.00235335 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.576\n",
      "INFO:tensorflow:step = 25001, loss = 0.000118122 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.555\n",
      "INFO:tensorflow:step = 25101, loss = 0.00184492 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.344\n",
      "INFO:tensorflow:step = 25201, loss = 0.00320799 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.582\n",
      "INFO:tensorflow:step = 25301, loss = 0.000183373 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.535\n",
      "INFO:tensorflow:step = 25401, loss = 0.000734714 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.591\n",
      "INFO:tensorflow:step = 25501, loss = 0.00117328 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.039\n",
      "INFO:tensorflow:step = 25601, loss = 0.00101388 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.814\n",
      "INFO:tensorflow:step = 25701, loss = 0.000994076 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.11\n",
      "INFO:tensorflow:step = 25801, loss = 0.00148109 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.301\n",
      "INFO:tensorflow:step = 25901, loss = 0.00150336 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.043\n",
      "INFO:tensorflow:step = 26001, loss = 4.42679e-05 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.853\n",
      "INFO:tensorflow:step = 26101, loss = 0.000945769 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.342\n",
      "INFO:tensorflow:step = 26201, loss = 0.000692925 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 509.125\n",
      "INFO:tensorflow:step = 26301, loss = 0.000701611 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.45\n",
      "INFO:tensorflow:step = 26401, loss = 0.00164209 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.236\n",
      "INFO:tensorflow:step = 26501, loss = 0.000905918 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.654\n",
      "INFO:tensorflow:step = 26601, loss = 0.000519783 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.507\n",
      "INFO:tensorflow:step = 26701, loss = 1.40954e-05 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.723\n",
      "INFO:tensorflow:step = 26801, loss = 0.000842135 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.259\n",
      "INFO:tensorflow:step = 26901, loss = 0.000808341 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.48\n",
      "INFO:tensorflow:step = 27001, loss = 0.000642265 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.043\n",
      "INFO:tensorflow:step = 27101, loss = 0.000423766 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.502\n",
      "INFO:tensorflow:step = 27201, loss = 0.000671817 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.07\n",
      "INFO:tensorflow:step = 27301, loss = 0.00108788 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.417\n",
      "INFO:tensorflow:step = 27401, loss = 0.000168051 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.232\n",
      "INFO:tensorflow:step = 27501, loss = 0.00143462 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.34\n",
      "INFO:tensorflow:step = 27601, loss = 0.000935573 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.969\n",
      "INFO:tensorflow:step = 27701, loss = 0.000289417 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.635\n",
      "INFO:tensorflow:step = 27801, loss = 0.000623281 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.737\n",
      "INFO:tensorflow:step = 27901, loss = 0.000400492 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.368\n",
      "INFO:tensorflow:step = 28001, loss = 0.00141883 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.593\n",
      "INFO:tensorflow:step = 28101, loss = 0.000513484 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.129\n",
      "INFO:tensorflow:step = 28201, loss = 0.00133993 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.369\n",
      "INFO:tensorflow:step = 28301, loss = 0.000679669 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.933\n",
      "INFO:tensorflow:step = 28401, loss = 0.000811346 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.943\n",
      "INFO:tensorflow:step = 28501, loss = 0.00057602 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.435\n",
      "INFO:tensorflow:step = 28601, loss = 0.000366546 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.609\n",
      "INFO:tensorflow:step = 28701, loss = 0.00086157 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.762\n",
      "INFO:tensorflow:step = 28801, loss = 0.00103206 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.979\n",
      "INFO:tensorflow:step = 28901, loss = 0.000274243 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.971\n",
      "INFO:tensorflow:step = 29001, loss = 0.00182547 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.434\n",
      "INFO:tensorflow:step = 29101, loss = 0.00104729 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.338\n",
      "INFO:tensorflow:step = 29201, loss = 0.001766 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.718\n",
      "INFO:tensorflow:step = 29301, loss = 0.00105772 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.731\n",
      "INFO:tensorflow:step = 29401, loss = 0.000961037 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.697\n",
      "INFO:tensorflow:step = 29501, loss = 0.00102937 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.75\n",
      "INFO:tensorflow:step = 29601, loss = 0.000430005 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.653\n",
      "INFO:tensorflow:step = 29701, loss = 0.00025649 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.765\n",
      "INFO:tensorflow:step = 29801, loss = 0.000605404 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.947\n",
      "INFO:tensorflow:step = 29901, loss = 0.00077305 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.642\n",
      "INFO:tensorflow:step = 30001, loss = 0.000108064 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.168\n",
      "INFO:tensorflow:step = 30101, loss = 0.000590002 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.635\n",
      "INFO:tensorflow:step = 30201, loss = 0.000234104 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.364\n",
      "INFO:tensorflow:step = 30301, loss = 0.00065963 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.92\n",
      "INFO:tensorflow:step = 30401, loss = 0.00115885 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.138\n",
      "INFO:tensorflow:step = 30501, loss = 0.000882715 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.08\n",
      "INFO:tensorflow:step = 30601, loss = 0.00145138 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.344\n",
      "INFO:tensorflow:step = 30701, loss = 0.000891694 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.627\n",
      "INFO:tensorflow:step = 30801, loss = 0.00118 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.907\n",
      "INFO:tensorflow:step = 30901, loss = 0.00115266 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.11\n",
      "INFO:tensorflow:step = 31001, loss = 0.000961674 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.588\n",
      "INFO:tensorflow:step = 31101, loss = 0.00149113 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.169\n",
      "INFO:tensorflow:step = 31201, loss = 0.000568497 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.278\n",
      "INFO:tensorflow:step = 31301, loss = 0.000460989 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 31401, loss = 0.000649023 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.962\n",
      "INFO:tensorflow:step = 31501, loss = 0.000197947 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.868\n",
      "INFO:tensorflow:step = 31601, loss = 6.59552e-05 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.649\n",
      "INFO:tensorflow:step = 31701, loss = 0.000625275 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.219\n",
      "INFO:tensorflow:step = 31801, loss = 9.4202e-05 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.543\n",
      "INFO:tensorflow:step = 31901, loss = 0.000756386 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.935\n",
      "INFO:tensorflow:step = 32001, loss = 0.000197061 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.246\n",
      "INFO:tensorflow:step = 32101, loss = 0.000425281 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.192\n",
      "INFO:tensorflow:step = 32201, loss = 0.00102074 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.823\n",
      "INFO:tensorflow:step = 32301, loss = 0.00041044 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.677\n",
      "INFO:tensorflow:step = 32401, loss = 0.000104019 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.832\n",
      "INFO:tensorflow:step = 32501, loss = 0.000511087 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.874\n",
      "INFO:tensorflow:step = 32601, loss = 0.000111053 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.442\n",
      "INFO:tensorflow:step = 32701, loss = 0.00126878 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.918\n",
      "INFO:tensorflow:step = 32801, loss = 0.000895224 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.33\n",
      "INFO:tensorflow:step = 32901, loss = 0.000406547 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.194\n",
      "INFO:tensorflow:step = 33001, loss = 0.000497633 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.187\n",
      "INFO:tensorflow:step = 33101, loss = 0.00210473 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.353\n",
      "INFO:tensorflow:step = 33201, loss = 0.000945465 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.81\n",
      "INFO:tensorflow:step = 33301, loss = 0.000309007 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.04\n",
      "INFO:tensorflow:step = 33401, loss = 0.00123292 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.151\n",
      "INFO:tensorflow:step = 33501, loss = 0.000225348 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.121\n",
      "INFO:tensorflow:step = 33601, loss = 0.000940695 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.672\n",
      "INFO:tensorflow:step = 33701, loss = 0.000726792 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.831\n",
      "INFO:tensorflow:step = 33801, loss = 0.00123973 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.865\n",
      "INFO:tensorflow:step = 33901, loss = 0.00107691 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.709\n",
      "INFO:tensorflow:step = 34001, loss = 0.000640319 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.46\n",
      "INFO:tensorflow:step = 34101, loss = 0.000919945 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.405\n",
      "INFO:tensorflow:step = 34201, loss = 0.00121334 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.634\n",
      "INFO:tensorflow:step = 34301, loss = 0.000127433 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.274\n",
      "INFO:tensorflow:step = 34401, loss = 0.000417725 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.86\n",
      "INFO:tensorflow:step = 34501, loss = 0.000630038 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.938\n",
      "INFO:tensorflow:step = 34601, loss = 0.000360699 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.556\n",
      "INFO:tensorflow:step = 34701, loss = 0.00173927 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.559\n",
      "INFO:tensorflow:step = 34801, loss = 0.000371267 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.911\n",
      "INFO:tensorflow:step = 34901, loss = 0.000374646 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.837\n",
      "INFO:tensorflow:step = 35001, loss = 0.000305932 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.046\n",
      "INFO:tensorflow:step = 35101, loss = 0.00104693 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.337\n",
      "INFO:tensorflow:step = 35201, loss = 0.000340343 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.486\n",
      "INFO:tensorflow:step = 35301, loss = 0.000153641 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.98\n",
      "INFO:tensorflow:step = 35401, loss = 0.000996451 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.299\n",
      "INFO:tensorflow:step = 35501, loss = 0.000171532 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.605\n",
      "INFO:tensorflow:step = 35601, loss = 0.000374124 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.507\n",
      "INFO:tensorflow:step = 35701, loss = 0.000663798 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.625\n",
      "INFO:tensorflow:step = 35801, loss = 0.000831119 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.283\n",
      "INFO:tensorflow:step = 35901, loss = 0.000574592 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.144\n",
      "INFO:tensorflow:step = 36001, loss = 0.000313818 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.048\n",
      "INFO:tensorflow:step = 36101, loss = 0.00114753 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.719\n",
      "INFO:tensorflow:step = 36201, loss = 0.000859921 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.624\n",
      "INFO:tensorflow:step = 36301, loss = 9.09132e-05 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.566\n",
      "INFO:tensorflow:step = 36401, loss = 0.000575347 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.811\n",
      "INFO:tensorflow:step = 36501, loss = 0.000190056 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.573\n",
      "INFO:tensorflow:step = 36601, loss = 0.000239809 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.388\n",
      "INFO:tensorflow:step = 36701, loss = 0.00044674 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.853\n",
      "INFO:tensorflow:step = 36801, loss = 0.000904511 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.662\n",
      "INFO:tensorflow:step = 36901, loss = 0.000720104 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.471\n",
      "INFO:tensorflow:step = 37001, loss = 0.000412932 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.344\n",
      "INFO:tensorflow:step = 37101, loss = 0.000163695 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.863\n",
      "INFO:tensorflow:step = 37201, loss = 0.000264861 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.072\n",
      "INFO:tensorflow:step = 37301, loss = 0.000719457 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.282\n",
      "INFO:tensorflow:step = 37401, loss = 0.000339975 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.288\n",
      "INFO:tensorflow:step = 37501, loss = 0.000324403 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.126\n",
      "INFO:tensorflow:step = 37601, loss = 0.000306283 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.381\n",
      "INFO:tensorflow:step = 37701, loss = 0.000100169 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.454\n",
      "INFO:tensorflow:step = 37801, loss = 0.000432111 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.819\n",
      "INFO:tensorflow:step = 37901, loss = 0.00140533 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.368\n",
      "INFO:tensorflow:step = 38001, loss = 0.000294866 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.316\n",
      "INFO:tensorflow:step = 38101, loss = 0.00119604 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.578\n",
      "INFO:tensorflow:step = 38201, loss = 0.000891358 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.289\n",
      "INFO:tensorflow:step = 38301, loss = 0.000129545 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.936\n",
      "INFO:tensorflow:step = 38401, loss = 0.000193591 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.257\n",
      "INFO:tensorflow:step = 38501, loss = 0.00049303 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.553\n",
      "INFO:tensorflow:step = 38601, loss = 0.000675174 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.38\n",
      "INFO:tensorflow:step = 38701, loss = 0.000358051 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.47\n",
      "INFO:tensorflow:step = 38801, loss = 0.000242674 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.584\n",
      "INFO:tensorflow:step = 38901, loss = 0.00127899 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.397\n",
      "INFO:tensorflow:step = 39001, loss = 0.000262657 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.398\n",
      "INFO:tensorflow:step = 39101, loss = 0.000705544 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.768\n",
      "INFO:tensorflow:step = 39201, loss = 0.000659797 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.256\n",
      "INFO:tensorflow:step = 39301, loss = 0.000316944 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.112\n",
      "INFO:tensorflow:step = 39401, loss = 0.000639012 (0.216 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 498.677\n",
      "INFO:tensorflow:step = 39501, loss = 0.000241011 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.027\n",
      "INFO:tensorflow:step = 39601, loss = 0.000744708 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.95\n",
      "INFO:tensorflow:step = 39701, loss = 0.000178735 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.325\n",
      "INFO:tensorflow:step = 39801, loss = 0.00115475 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.747\n",
      "INFO:tensorflow:step = 39901, loss = 0.00126455 (0.200 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into C:\\Users\\hugoj\\AppData\\Local\\Temp\\tmpims7vzmp\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000402969.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.contrib.learn.RunConfig(tf_random_seed=42) # not shown in the config\n",
    "\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300,100], n_classes=10,\n",
    "                                         feature_columns=feature_cols, config=config)\n",
    "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf) # if TensorFlow >= 1.1\n",
    "dnn_clf.fit(X_train, y_train, batch_size=50, steps=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hugoj\\AppData\\Local\\Temp\\tmpims7vzmp\\model.ckpt-40000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98209999999999997"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = dnn_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred['classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a DNN Using Plain TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want more controll over the structure of your NN, use the lower-level Python API to train your network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Construction Phase*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing TensorFlow and specifiying the number of inputs, outputs, and neurons per layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify your placeholder nodes for the inputs. We don't know how many instances we are going to get to so leave the number of rows as **None**. The same is true for the label placeholders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function that will handle creating the NN layers for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name): # Create a scope for this layer so that it looks nice on TensorBoard\n",
    "        n_inputs = int(X.get_shape()[1]) # Determine input number by looking at 2nd dimension of input\n",
    "        \n",
    "        # Create a radmomly initialized variable W that holds all the weights for the layer\n",
    "        stddev = 2 / np.sqrt(n_inputs)  \n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        \n",
    "        # Creates one bias parameter per neuron, can be set to 0 with no symetry issues\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        \n",
    "        # Node to compute X * W + b\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        \n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    # first layer takes X as input\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "    \n",
    "    # takes the 1st hidden layer as input\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "    \n",
    "    # takes the 2nd hidden layer as input \n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can have tensorflow do everything our function does automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: tensorflow.contrib is for experimental code that has yet to be fully added to the api \n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = fully_connected(X, n_hidden1, scope=\"hidden1\")\n",
    "    hidden2 = fully_connected(hidden1, n_hidden2, scope=\"hidden2\")\n",
    "    logits = fully_connected(hidden2, n_outputs, scope=\"outputs\", activation_fn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the error, we will use cross entropy. The function in tensorflow that we will use will compute the cross entropy based on the logits input **before** the softmax function. Thus we will get a 1D tensor we must use to compute the mean cross entropy over all instances: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our gradient descent optimizer is similar to the one used in Chapter 9: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify how we're going to evaluate the model. We're going to use accuracy for this case. So first we need to check if our NN correctly predicted the target lable. We use **in_top_k()** to do that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we intialize and create a saver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Execution Phase*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data and set your training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\") # Data is automatically scaled for us \n",
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next train your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.9 Test accuracy: 0.9036\n",
      "1 Train accuracy: 0.88 Test accuracy: 0.9218\n",
      "2 Train accuracy: 0.9 Test accuracy: 0.9307\n",
      "3 Train accuracy: 0.92 Test accuracy: 0.9378\n",
      "4 Train accuracy: 0.92 Test accuracy: 0.9434\n",
      "5 Train accuracy: 0.94 Test accuracy: 0.947\n",
      "6 Train accuracy: 0.96 Test accuracy: 0.9509\n",
      "7 Train accuracy: 0.94 Test accuracy: 0.954\n",
      "8 Train accuracy: 0.96 Test accuracy: 0.958\n",
      "9 Train accuracy: 0.96 Test accuracy: 0.9604\n",
      "10 Train accuracy: 0.96 Test accuracy: 0.9619\n",
      "11 Train accuracy: 0.92 Test accuracy: 0.9645\n",
      "12 Train accuracy: 0.98 Test accuracy: 0.9666\n",
      "13 Train accuracy: 0.96 Test accuracy: 0.9648\n",
      "14 Train accuracy: 1.0 Test accuracy: 0.9683\n",
      "15 Train accuracy: 1.0 Test accuracy: 0.9688\n",
      "16 Train accuracy: 1.0 Test accuracy: 0.9691\n",
      "17 Train accuracy: 0.94 Test accuracy: 0.97\n",
      "18 Train accuracy: 1.0 Test accuracy: 0.9706\n",
      "19 Train accuracy: 1.0 Test accuracy: 0.9712\n",
      "20 Train accuracy: 1.0 Test accuracy: 0.9713\n",
      "21 Train accuracy: 1.0 Test accuracy: 0.9718\n",
      "22 Train accuracy: 0.98 Test accuracy: 0.9718\n",
      "23 Train accuracy: 0.98 Test accuracy: 0.9747\n",
      "24 Train accuracy: 1.0 Test accuracy: 0.9735\n",
      "25 Train accuracy: 1.0 Test accuracy: 0.9751\n",
      "26 Train accuracy: 0.98 Test accuracy: 0.9742\n",
      "27 Train accuracy: 1.0 Test accuracy: 0.9748\n",
      "28 Train accuracy: 0.96 Test accuracy: 0.9761\n",
      "29 Train accuracy: 0.98 Test accuracy: 0.9763\n",
      "30 Train accuracy: 1.0 Test accuracy: 0.9772\n",
      "31 Train accuracy: 1.0 Test accuracy: 0.9765\n",
      "32 Train accuracy: 0.98 Test accuracy: 0.9767\n",
      "33 Train accuracy: 1.0 Test accuracy: 0.9759\n",
      "34 Train accuracy: 0.98 Test accuracy: 0.9777\n",
      "35 Train accuracy: 0.98 Test accuracy: 0.9775\n",
      "36 Train accuracy: 0.98 Test accuracy: 0.9775\n",
      "37 Train accuracy: 0.98 Test accuracy: 0.9784\n",
      "38 Train accuracy: 1.0 Test accuracy: 0.9786\n",
      "39 Train accuracy: 1.0 Test accuracy: 0.9784\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                            y: mnist.test.labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Using the Neural Network*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use your newly trained NN, all you need to do is make changes to the execution phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\") # or better, use save_path\n",
    "    X_new_scaled = mnist.test.images[:20]\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to find the optimium hyperparameters for your NN, you're better off conducting a random search or using an external tool. This is due to the fact that the number of possible combinations of hyperparameters for a NN is to high. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Number of Hidden Layers*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually one hidden layer is all you need. However, DNNs have much higher *parameter efficiency*. This means they can model complex functions using fewer neurons. Therefore start with one or two layers and keep adding more until your DNN starts to overfit the data. \n",
    "\n",
    "The first layers capture fundamental components, the next layers capture fundamental structures, and the last layers put it all together to try and model the high level structure of your data. This is why you can intialize your first layers to match those of previously trained NNs that are tackling similar datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Nunber of Neurons per Hidden Layer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to form a funnel of sorts when structuring your network. Each layer should have fewer and fewer neurons in order for each layer to try and capture higher level structures. \n",
    "\n",
    "Typically its better to add more layers than it is to add more neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Activation Functions*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU is good for most cases as GD doesn't tend to get stuck as often using that activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
